{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import mymain\n",
    "\n",
    "seed = 1735\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dir = './F24_Proj3_data/split_1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(texts):\n",
    "    # Load pre-trained model and tokenizer\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def get_sentence_embedding(text):\n",
    "        inputs = bert_tokenizer(text, truncation=True, padding=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        sentence_embedding = torch.mean(last_hidden_states, dim=1).numpy().flatten()\n",
    "        return sentence_embedding\n",
    "\n",
    "    # Generate embeddings for texts\n",
    "    return np.array([get_sentence_embedding(text) for text in tqdm(texts)])\n",
    "\n",
    "\n",
    "def get_embeddings(filepath, num):\n",
    "    test_df = pd.read_csv(filepath)\n",
    "    X_test = test_df.drop(columns=['id', 'review'])\n",
    "\n",
    "    idxs = np.random.choice(len(X_test), size=num, replace=False)\n",
    "\n",
    "    reviews = test_df.iloc[idxs]['review'].tolist()\n",
    "    bert = get_bert_embeddings(reviews)\n",
    "    assert bert.shape == (num, 768)\n",
    "\n",
    "    openai = test_df.iloc[idxs].drop(columns=['id', 'review']).to_numpy()\n",
    "    assert openai.shape == (num, 1536)\n",
    "\n",
    "    return bert, openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4eefe47623f444c9d91d2d315ef6ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((1600, 768), (1600, 1536))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert, openai = get_embeddings(join(split_dir, 'test.csv'), 1600)\n",
    "bert.shape, openai.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(769, 1536)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.c_[np.ones(bert.shape[0]), bert]\n",
    "x, _, _, _ = np.linalg.lstsq(X, openai)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write trained split 1 model to file\n",
    "\n",
    "cwd = os.getcwd()\n",
    "os.chdir(split_dir)\n",
    "model = mymain.main()\n",
    "os.chdir(cwd)\n",
    "\n",
    "model_file = './interpretability_inputs/trained_lr_model.npz'\n",
    "np.savez_compressed(model_file, intercept=model.intercept_, coef=model.coef_, features=model.feature_names_in_, bert_to_openai_mapping=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = join(split_dir, \"test.csv\")\n",
    "\n",
    "# Load true labels data\n",
    "test_df = pd.read_csv(test_path)\n",
    "X_test = test_df.drop(columns=['id', 'review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5694,  9920, 14168,  4549, 14891]),\n",
       " array([20452,  5722,  6566,  2753,  1055]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "np.random.seed(seed)\n",
    "pos_idxs = np.random.choice(np.where(probs > 0.5)[0], 5, replace=False)\n",
    "neg_idxs = np.random.choice(np.where(probs < 0.5)[0], 5, replace=False)\n",
    "pos_idxs, neg_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d407d5ff1240ab8399d11e409e0d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./interpretability_inputs/pos_2603.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd9fa07bd1c4993a1dd288cb3c52928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./interpretability_inputs/pos_8073.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d319457b35042b78b03b339339352a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./interpretability_inputs/pos_19034.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4bec88bd924ed0be3d0b31e605ece5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./interpretability_inputs/pos_17545.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca5620af53448f8b1ae4c8a797c35ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./interpretability_inputs/pos_9595.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498b439a19ce45a2831866673acdaf5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./interpretability_inputs/neg_35754.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912bd815c60845d4b528c743f03e6b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./interpretability_inputs/neg_10557.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24725c1542ce45a199a751a7db9b7c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./interpretability_inputs/neg_46871.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd7ad36e8a14ea38dc7695882aa99fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./interpretability_inputs/neg_41564.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a45027aa85484f85332c394e899d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ./interpretability_inputs/neg_2726.csv\n"
     ]
    }
   ],
   "source": [
    "pos_idxs = np.array([ 5694,  9920, 14168,  4549, 14891])\n",
    "neg_idxs = np.array([20452,  5722,  6566,  2753,  1055])\n",
    "\n",
    "\n",
    "def generate_interpretability_embeddings(tag, id, review):\n",
    "    sentences = review.split('.')\n",
    "    loo_reviews = []\n",
    "    for idx in range(len(sentences)):\n",
    "        loo_reviews.append('. '.join(sentences[:idx] + sentences[idx + 1:]))\n",
    "    loo_berts = get_bert_embeddings(loo_reviews)\n",
    "    \n",
    "    data = np.c_[np.array(sentences), loo_berts]\n",
    "    columns = ['loo_sentence'] + [f'bert_embedding_{idx + 1}' for idx in range(loo_berts.shape[1])]\n",
    "    data_filepath = join(f'./interpretability_inputs/{tag}_{id}.csv')\n",
    "    print(f'Writing to {data_filepath}')\n",
    "    pd.DataFrame(data, columns=columns).to_csv(data_filepath, index=False, header=True)\n",
    "\n",
    "\n",
    "for tag, review_idxs in [('pos', pos_idxs), ('neg', neg_idxs)]:\n",
    "    for review_idx in review_idxs:\n",
    "        generate_interpretability_embeddings(tag, test_df.iloc[review_idx].id, test_df.iloc[review_idx].review)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj3_interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
